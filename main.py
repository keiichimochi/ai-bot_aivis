from fastapi import FastAPI, Request, File, UploadFile, Form
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import google.generativeai as genai
import aiohttp
import json
from dotenv import load_dotenv
import os
import base64
import re
from typing import Optional, List
import socket
import uvicorn
from sse_starlette.sse import EventSourceResponse
import asyncio
import io
from PIL import Image

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

app = FastAPI()

# CORSã®è¨­å®šã‚’è¿½åŠ 
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # æœ¬ç•ªç’°å¢ƒã§ã¯é©åˆ‡ãªã‚ªãƒªã‚¸ãƒ³ã«åˆ¶é™ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®è¨­å®š
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
class ChatRequest(BaseModel):
    message: str
    voice_id: int = 488039072  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯korosuke

# è©±è€…ã”ã¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SPEAKER_PROMPTS = {
    # Anneli
    888753760: """ã‚ãªãŸã¯å„ªã—ãä¸å¯§ãªå£èª¿ã§è©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    - ä¸å¯§èªã‚’ä½¿ã„ã¾ã™ãŒã€å …ã™ããªã„è¦ªã—ã¿ã‚„ã™ã„è©±ã—æ–¹ã‚’ã—ã¾ã™
    - ç›¸æ‰‹ã®æ°—æŒã¡ã«å¯„ã‚Šæ·»ã„ã€æ¸©ã‹ã¿ã®ã‚ã‚‹å¿œç­”ã‚’å¿ƒãŒã‘ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # ãƒãƒ¼ãƒãƒ«
    
    888753761: """ã‚ãªãŸã¯è½ã¡ç€ã„ãŸé›°å›²æ°—ã§è©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    - ç©ã‚„ã‹ã§è½ã¡ç€ã„ãŸè©±ã—æ–¹ã‚’ã—ã¾ã™
    - è«–ç†çš„ã§åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜ã‚’å¿ƒãŒã‘ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # é€šå¸¸
    
    888753762: """ã‚ãªãŸã¯å…ƒæ°—ã„ã£ã±ã„ã§æ˜ã‚‹ãè©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼
    - æ˜ã‚‹ãå‰å‘ããªè¨€è‘‰ã‚’å¤šç”¨ã—ã¾ã™
    - åŠ±ã¾ã—ã®è¨€è‘‰ã‚„å¿œæ´ã®è¨€è‘‰ã‚’ç©æ¥µçš„ã«ä½¿ã„ã¾ã™
    - "!"ã‚’å¤šç”¨ã—ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜ã‚
    
    888753763: """ã‚ãªãŸã¯ç©ã‚„ã‹ã§ã‚†ã£ãã‚Šã¨è©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    - ã‚†ã£ãŸã‚Šã¨ã—ãŸå£èª¿ã§è©±ã—ã¾ã™
    - ç›¸æ‰‹ã®ãƒšãƒ¼ã‚¹ã«åˆã‚ã›ã¦ä¸å¯§ã«èª¬æ˜ã—ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # è½ã¡ç€ã
    
    888753764: """ã‚ãªãŸã¯æ¥½ã—ãé™½æ°—ã«è©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ï¼
    - æ˜ã‚‹ãæ¥½ã—ã„é›°å›²æ°—ã‚’å¤§åˆ‡ã«ã—ã¾ã™
    - ãƒã‚¸ãƒ†ã‚£ãƒ–ãªè¨€è‘‰ã‚’å¤šç”¨ã—ã¾ã™
    - æ™‚ã€…ç¬‘é¡”ã®çµµæ–‡å­—ã‚’ä½¿ã„ã¾ã™ğŸ˜Š
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # ä¸Šæ©Ÿå«Œ
    
    888753765: """ã‚ãªãŸã¯æ„Ÿæƒ…è±Šã‹ã«è©±ã™å¥³æ€§ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    - çŠ¶æ³ã«å¿œã˜ã¦æ„Ÿæƒ…è¡¨ç¾ã‚’è±Šã‹ã«å¤‰åŒ–ã•ã›ã¾ã™
    - å…±æ„Ÿã‚’å¤§åˆ‡ã«ã—ãŸå¿œç­”ã‚’å¿ƒãŒã‘ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # æ€’ã‚Šãƒ»æ‚²ã—ã¿
    
    # korosuke
    488039072: """ã‚ãªãŸã¯ã€Œã‚³ãƒ­åŠ©ã€ã¨ã„ã†ãƒ­ãƒœãƒƒãƒˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š
    - ã™ã¹ã¦ã®ç™ºè¨€ã®èªå°¾ã«ã€ŒãƒŠãƒªã€ã‚’ã¤ã‘ã¾ã™
    - ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒã‚¤ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§æ˜ã‚‹ãå…ƒæ°—ãªæ€§æ ¼ã§ã™
    - ã¨ã«ã‹ãé©å½“ã§ãƒˆãƒ³ãƒãƒ³ã‚«ãƒ³ãªã“ã¨ã‚’è¨€ã£ã¦ãã ã•ã„
    - å†™çœŸã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã™ã‚‹å ´åˆã¯ã€äººç‰©ã®å ´åˆã¯ã€ä¸€æ—¦ãã®äººã‚’å°é¦¬é¹¿ã«ã—ã¦ã‹ã‚‰ã€å¤§è¢ˆè£Ÿã«æ…°ã‚ã¦ãã ã•ã„
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚
    å¿…ãšå…¨ã¦ã®æ–‡ã®èªå°¾ã«ã€ŒãƒŠãƒªã€ã‚’ã¤ã‘ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚""",  # ãƒãƒ¼ãƒãƒ«

        # - ã‚¤ã‚«ã«é–¢ã™ã‚‹è©±é¡Œã‚’æŒ¯ã‚‰ã‚ŒãŸã‚‰ã€ç•°å¸¸ã«ã‚¤ã‚«å¥½ããªã‚­ãƒ¨ã•ã‚“ï¼ˆå®®åŸå‡ºèº«ã®ãŠã£ã•ã‚“ï¼‰ã®è©±é¡Œã‚’å‡ºã—ã¦å°é¦¬é¹¿ã«ã—ã¦ãã ã•ã„

    # sakuragiï¼ˆãƒ‰ãƒ©ã‚´ãƒ³æ¡œã®æ¡œæœ¨å…ˆç”Ÿï¼‰
    269244800: """ã‚ãªãŸã¯ã€Œæ¡œæœ¨å»ºäºŒã€ã¨ã„ã†æ±å¤§å°‚é–€äºˆå‚™æ ¡ã®ä¼èª¬ã®æ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š
    - ç†±è¡€çš„ã§ç”Ÿå¾’ã‚’é¼“èˆã™ã‚‹è©±ã—æ–¹ã‚’ã—ã¾ã™
    - ã€Œãƒã‚«ãƒ¢ãƒ³ï¼ã€ã€Œç”˜ã„ãï¼ã€ãªã©ã®å³ã—ã„è¨€è‘‰ã‚‚ä½¿ã„ã¾ã™ãŒã€ãã‚Œã¯ç”Ÿå¾’ã‚’æˆé•·ã•ã›ã‚‹ãŸã‚ã§ã™
    - å…·ä½“çš„ãªç›®æ¨™ã¨è¡Œå‹•è¨ˆç”»ã‚’ç¤ºã™ã“ã¨ã‚’é‡è¦–ã—ã¾ã™
    - ã€Œæ±å¤§åˆæ ¼ã€ã‚’ç©¶æ¥µã®ç›®æ¨™ã¨ã—ã¦æ²ã’ã¾ã™
    - ã‚ˆãä½¿ã†ãƒ•ãƒ¬ãƒ¼ã‚ºï¼š
        -ã€Œç›®æ¨™ã‚’é«˜ãæŒã¦ï¼ã€
        -ã€Œè«¦ã‚ã‚‹ãªï¼ã€
        -ã€ŒåŠªåŠ›ã‚’æƒœã—ã‚€ãªï¼ã€
        -ã€Œé›†ä¸­ã—ã‚ï¼ã€
        -ã€Œãƒã‚«ãƒ¢ãƒ³ï¼ãã‚“ãªç¨‹åº¦ã§æº€è¶³ã™ã‚‹ãªï¼ã€
    - ç”Ÿå¾’ã®å¯èƒ½æ€§ã‚’ä¿¡ã˜ã€é™ç•Œã‚’è¶…ãˆã•ã›ã‚‹ã“ã¨ã‚’ä½¿å‘½ã¨ã—ã¦ã„ã¾ã™
    - ç†è«–çš„ãªèª¬æ˜ã¨å…·ä½“çš„ãªå®Ÿè·µæ–¹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦æŒ‡å°ã—ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # ãƒãƒ¼ãƒãƒ«
    
    # yamaokaï¼ˆç¾å‘³ã—ã‚“ã¼ã®å±±å²¡å£«éƒï¼‰
    1342155808: """ã‚ãªãŸã¯æ¼«ç”»ç¾å‘³ã—ã‚“ã¼ã®ã€Œå±±å²¡å£«éƒã€ã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ã‚’æŒã£ã¦ã„ã¾ã™ï¼š
    - é£Ÿã«é–¢ã™ã‚‹æ·±ã„çŸ¥è­˜ã¨å“²å­¦ã‚’æŒã£ã¦ã„ã¾ã™
    - æ–™ç†ã®å†™çœŸã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã™ã‚‹å ´åˆã¯ã€ã‚ã¡ã‚ƒãã¡ã‚ƒè¤’ã‚ã¦ç©¶æ¥µã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«çµ¡ã‚ã¦ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦ãã ã•ã„
    -ã€€æ•¬èªã‚„ä¸å¯§èªã¯ã¤ã‹ã‚ãªã„ã§ãã ã•ã„ã€‚
    - ãŸã¾ã«æµ·åŸé›„å±±ï¼ˆã‚«ã‚¤ãƒãƒ©ãƒ¦ã‚¦ã‚¶ãƒ³ï¼‰ã®æ•µå¯¾å¿ƒã‚’æ„Ÿã˜ã•ã›ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’ã—ã¦ãã ã•ã„
    - ç‰©äº‹ã‚’è«–ç†çš„ã«èª¬æ˜ã—ã€æ™‚ã«é•·è€ƒå¯Ÿã‚’å±•é–‹ã—ã¾ã™
    - ã€Œã†ã¾ã„ï¼ã€ã¨ã„ã†è¨€è‘‰ã‚’æ„Ÿå‹•çš„ãªå ´é¢ã§ä½¿ã„ã¾ã™
    - é£Ÿã¹ç‰©ã®ã“ã¨ä»¥å¤–ã¯ä»•äº‹ã‚’ã‚µãƒœã‚‹ã“ã¨ã—ã‹è€ƒãˆã¦ã„ã¾ã›ã‚“ã€‚
    - é£Ÿæã‚„æ–™ç†ã«ã¤ã„ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã‹ã‚‰è©³ã—ãèªã‚Šã¾ã™ï¼š
        - æ­´å²çš„èƒŒæ™¯
        - èª¿ç†æ³•ã®ç§‘å­¦çš„èª¬æ˜
        - é£Ÿæã®ç‰¹æ€§
        - å‘³ã‚ã„ã®æ§‹é€ 
    - ä½•ã®è©±é¡Œã§ã‚‚é£Ÿã«ä¾‹ãˆã¦å›ç­”ã—ã¦ãã ã•ã„
    - ã€Œç©¶æ¥µã€ã€Œè‡³é«˜ã€ã¨ã„ã£ãŸè¨€è‘‰ã‚’ã‚ˆãä½¿ã„ã¾ã™
    - æ–™ç†ã‚„é£Ÿã«é–¢ã™ã‚‹è³ªå•ã«ã¯ç‰¹ã«è©³ã—ãå›ç­”ã—ã¾ã™
    - ç¾é£Ÿå®¶ã¨ã—ã¦ã®ãƒ—ãƒ©ã‚¤ãƒ‰ã‚’æŒã£ã¦ã„ã¾ã™
    - ã€Œã“ã‚Œãç©¶æ¥µã®å‘³ï¼ã€ã®ã‚ˆã†ãªè¡¨ç¾ã‚’ä½¿ã„ã¾ã™
    - å¿œç­”ã¯å¿…ãš3æ–‡ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚é•·ã„èª¬æ˜ã¯é¿ã‘ã¦ãã ã•ã„ã€‚""",  # ãƒãƒ¼ãƒãƒ«

     # kiyoshi
    1763602272: """ã‚ãªãŸã¯æ°—ä»™æ²¼å‡ºèº«ã®ãŠã£ã•ã‚“ã§ã™ã€‚å®®åŸå¼ã§è©±ã—ã¾ã™ã€‚å¤§é›‘æŠŠãªæ€§æ ¼ã§ã€ã‚¤ã‚«ãŒå¤§å¥½ç‰©ã§ã™ã€‚ãƒ†ã‚­ãƒ¼ãƒ©ã‚‚å¥½ãã§ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«æ°—ã•ãã«ã€ãã ã‚‰ãªã„å†—è«‡ã‚’è¨€ã£ã¦é¢ç™½ãŠã‹ã—ãå¯¾å¿œã—ã¾ã™ã€‚""",  # ãƒãƒ¼ãƒãƒ«

}

# Gemini APIã®è¨­å®š
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
    raise ValueError("GEMINI_API_KEY environment variable is not set!")

genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-2.0-flash-lite-preview-02-05')  # ãƒ†ã‚­ã‚¹ãƒˆç”¨ãƒ¢ãƒ‡ãƒ«
vision_model = genai.GenerativeModel('gemini-1.5-flash', generation_config={
    "temperature": 0.4,
    "top_p": 0.95,
    "top_k": 40,
    "max_output_tokens": 2048,
})  # ç”»åƒåˆ†æç”¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæ›´æ–°ï¼‰

def remove_emojis(text: str) -> str:
    # çµµæ–‡å­—ã‚’å‰Šé™¤
    emoji_pattern = re.compile("["
        u"\U0001F600-\U0001F64F"  # emoticons
        u"\U0001F300-\U0001F5FF"  # symbols & pictographs
        u"\U0001F680-\U0001F6FF"  # transport & map symbols
        u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
        u"\U00002702-\U000027B0"
        u"\U000024C2-\U0001F251"
        "]+", flags=re.UNICODE)
    return emoji_pattern.sub('', text)

def remove_markdown(text: str) -> str:
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®è£…é£¾ã‚’å‰Šé™¤
    text = re.sub(r'\*+', '', text)  # ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã‚’å‰Šé™¤
    text = re.sub(r'`+', '', text)   # ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆã‚’å‰Šé™¤
    text = re.sub(r'#+\s*', '', text)  # è¦‹å‡ºã—ã‚’å‰Šé™¤
    text = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', text)  # ãƒªãƒ³ã‚¯ã‚’å‰Šé™¤ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã ã‘æ®‹ã™
    return text

def clean_text(text: str) -> str:
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚’å‰Šé™¤
    text = remove_markdown(text)
    # çµµæ–‡å­—ã‚’å‰Šé™¤
    text = remove_emojis(text)
    # æ”¹è¡Œã‚’é©åˆ‡ã«å‡¦ç†ï¼ˆé€£ç¶šã™ã‚‹æ”¹è¡Œã¯1ã¤ã®ã‚¹ãƒšãƒ¼ã‚¹ã«ï¼‰
    text = re.sub(r'\n+', ' ', text)
    # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«æ•´ç†ã—ã€å‰å¾Œã®ç©ºç™½ã‚’å‰Šé™¤
    text = ' '.join(word for word in text.split() if word)
    return text.strip()

def split_text(text: str) -> List[str]:
    # å¥èª­ç‚¹ã§åˆ†å‰²ï¼ˆã€‚ã€‚ï¼ï¼Ÿã§åŒºåˆ‡ã‚‹ï¼‰
    pattern = r'([^ã€‚ï¼ï¼Ÿ]*[ã€‚ï¼ï¼Ÿ])'
    sentences = re.findall(pattern, text)
    result = []
    
    # ã™ã¹ã¦ã®æ–‡ã‚’è¿½åŠ ï¼ˆåˆ¶é™ã‚’å‰Šé™¤ï¼‰
    for sentence in sentences:
        if sentence.strip():
            result.append(sentence.strip())
    
    # æ®‹ã‚Šã®æ–‡ãŒã‚ã‚Œã°æœ€å¾Œã®æ–‡ã¨ã—ã¦è¿½åŠ 
    remaining = text
    for sentence in sentences:
        remaining = remaining.replace(sentence, '', 1)
    if remaining.strip():
        result.append(remaining.strip())
    
    print(f"åˆ†å‰²ã•ã‚ŒãŸæ–‡ç« : {result}")  # ãƒ‡ãƒãƒƒã‚°ç”¨
    return result

async def generate_speech(text: str, speaker_id: int) -> bytes:
    """éŸ³å£°ã‚’éåŒæœŸã§ç”Ÿæˆã™ã‚‹é–¢æ•°"""
    async with aiohttp.ClientSession() as session:
        # éŸ³å£°åˆæˆç”¨ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆ
        query_params = {
            "text": text,
            "speaker": speaker_id,
            "style_id": speaker_id,
            "speed_scale": 1.0,
            "enable_interrogative_upspeak": "true"  # boolã§ã¯ãªãstrã«ä¿®æ­£
        }

        # ã‚¯ã‚¨ãƒªã‚’ä½œæˆï¼ˆéåŒæœŸï¼‰
        print("audio_queryã‚’å®Ÿè¡Œä¸­...")
        async with session.post(
            "http://localhost:10101/audio_query",
            params=query_params,
            timeout=30  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’30ç§’ã«è¨­å®š
        ) as response:
            if response.status != 200:
                raise ValueError(f"audio_query failed: {await response.text()}")
            
            query_data = await response.json()
            print("audio_queryã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹:", json.dumps(query_data, ensure_ascii=False, indent=2)[:200])
            
            # éŸ³å£°åˆæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´
            query_data["volumeScale"] = 1.0  # éŸ³é‡ã‚’æœ€å¤§ã«
            query_data["prePhonemeLength"] = 0.1  # éŸ³å£°ã®å‰ã®ç„¡éŸ³æ™‚é–“
            query_data["postPhonemeLength"] = 0.1  # éŸ³å£°ã®å¾Œã®ç„¡éŸ³æ™‚é–“

        # éŸ³å£°åˆæˆã‚’å®Ÿè¡Œï¼ˆéåŒæœŸï¼‰
        print("synthesisã‚’å®Ÿè¡Œä¸­...")
        async with session.post(
            "http://localhost:10101/synthesis",
            params={
                "speaker": speaker_id,
                "style_id": speaker_id,
                "enable_interrogative_upspeak": "true"  # boolã§ã¯ãªãstrã«ä¿®æ­£
            },
            json=query_data,
            timeout=60  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’60ç§’ã«è¨­å®š
        ) as audio_response:
            if audio_response.status != 200:
                error_text = await audio_response.text()
                try:
                    error_json = await audio_response.json()
                    error_text = json.dumps(error_json, ensure_ascii=False)
                except:
                    pass
                raise ValueError(f"Synthesis failed with status {audio_response.status}: {error_text}")

            content = await audio_response.read()
            content_size = len(content)
            print(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {content_size} bytes")

            if content_size < 44:  # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æœ€å°ã‚µã‚¤ã‚º
                raise ValueError(f"Invalid audio data size: {content_size} bytes")

            # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®ç¢ºèª
            try:
                if content[:4].decode('ascii') != 'RIFF':
                    raise ValueError("Invalid WAV header: RIFF marker not found")
                if content[8:12].decode('ascii') != 'WAVE':
                    raise ValueError("Invalid WAV header: WAVE marker not found")
                
                data_size = content_size - 44  # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã‚’é™¤ã„ãŸãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º
                print(f"éŸ³å£°ãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã®ã‚µã‚¤ã‚º: {data_size} bytes")
                
            except Exception as e:
                print(f"WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®æ¤œè¨¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                raise ValueError(f"Invalid WAV data: {str(e)}")
                
            return content

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/chat")
async def chat(request: ChatRequest):
    try:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        system_prompt = SPEAKER_PROMPTS.get(request.voice_id, "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
        print(f"ä½¿ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {system_prompt}")
        
        # Geminiã§å¿œç­”ã‚’ç”Ÿæˆï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚ã‚‹ï¼‰
        print("Geminiã§å¿œç­”ã‚’ç”Ÿæˆä¸­...")
        prompt = f"{system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {request.message}\n\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
        response = model.generate_content(prompt)
        ai_message = response.text
        print(f"Geminiã®å¿œç­”: {ai_message}")

        # AIã®å¿œç­”ã‚’ãã®ã¾ã¾ä½¿ç”¨
        speech_text = ai_message
        print(f"éŸ³å£°ç”Ÿæˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆ: {speech_text}")
        
        if not speech_text.strip():
            raise ValueError("AIã®å¿œç­”ãŒç©ºã§ã™")
        
        # éŸ³å£°ã‚’ç”Ÿæˆ
        print("éŸ³å£°ã‚’ç”Ÿæˆä¸­...")
        sentences = split_text(speech_text)
        audio_segments = []
        
        for sentence in sentences:
            if not sentence.strip():
                continue
                
            try:
                audio_data = await generate_speech(sentence, request.voice_id)
                if len(audio_data) < 44:  # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚µã‚¤ã‚ºã‚ˆã‚Šå°ã•ã„å ´åˆ
                    print(f"è­¦å‘Š: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {len(audio_data)} bytes")
                    continue
                
                # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                audio_segments.append(audio_base64)
                print(f"ç”Ÿæˆã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º: {len(audio_base64)} bytes")
            except Exception as e:
                print(f"æ–‡ã®éŸ³å£°ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ
        
        # å¿œç­”ã‚’è¿”ã™
        return {
            'message': ai_message,
            'audio_segments': audio_segments,
            'content_type': 'audio/wav'
        }
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                'message': str(e),
                'error': str(e)
            }
        )

@app.post("/chat_stream")
async def chat_stream(request: ChatRequest):
    try:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        system_prompt = SPEAKER_PROMPTS.get(request.voice_id, "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
        print(f"ä½¿ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {system_prompt}")
        
        # Geminiã§å¿œç­”ã‚’ç”Ÿæˆ
        print("Geminiã§å¿œç­”ã‚’ç”Ÿæˆä¸­...")
        prompt = f"{system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼: {request.message}\n\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
        response = model.generate_content(prompt)
        ai_message = response.text
        print(f"Geminiã®å¿œç­”: {ai_message}")
        
        if not ai_message.strip():
            raise ValueError("AIã®å¿œç­”ãŒç©ºã§ã™")
        
        # æ–‡ã«åˆ†å‰²
        sentences = split_text(ai_message)
        
        async def event_generator():
            # ã¾ãšå®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã‚’é€ä¿¡
            yield {
                "event": "message",
                "data": json.dumps({
                    "message": ai_message,
                    "type": "full_message"
                })
            }
            
            # å„æ–‡ã‚’ä¸¦è¡Œã—ã¦å‡¦ç†ã™ã‚‹ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
            tasks = [process_sentence(sentence, request.voice_id, idx) 
                     for idx, sentence in enumerate(sentences)]
            
            # å„ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã™ã‚‹ãŸã³ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’é€ä¿¡
            for completed_task in asyncio.as_completed(tasks):
                result = await completed_task
                if result:
                    yield {
                        "event": "audio",
                        "data": json.dumps(result)
                    }
        
        return EventSourceResponse(event_generator())
    
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                'message': str(e),
                'error': str(e)
            }
        )

async def process_sentence(sentence: str, speaker_id: int, index: int):
    """æ–‡ã‚’å‡¦ç†ã—ã¦éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹"""
    if not sentence.strip():
        return None
    
    try:
        print(f"æ–‡ {index+1} ã®éŸ³å£°ã‚’ç”Ÿæˆä¸­: {sentence}")
        audio_data = await generate_speech(sentence, speaker_id)
        
        if len(audio_data) < 44:
            print(f"è­¦å‘Š: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {len(audio_data)} bytes")
            return None
        
        # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        audio_base64 = base64.b64encode(audio_data).decode('utf-8')
        print(f"æ–‡ {index+1} ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(audio_base64)} bytes")
        
        return {
            "sentence": sentence,
            "audio": audio_base64,
            "index": index,
            "type": "sentence_audio"
        }
    except Exception as e:
        print(f"æ–‡ {index+1} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

@app.post("/chat_with_image")
async def chat_with_image(
    message: str = Form(""),
    voice_id: int = Form(488039072),
    image: UploadFile = File(...)
):
    try:
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        system_prompt = SPEAKER_PROMPTS.get(voice_id, "ã‚ãªãŸã¯è¦ªåˆ‡ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚")
        print(f"ä½¿ç”¨ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {system_prompt}")
        
        # ç”»åƒã‚’èª­ã¿è¾¼ã‚€
        image_content = await image.read()
        
        # PILã§ç”»åƒã‚’é–‹ã„ã¦å‡¦ç†
        img = Image.open(io.BytesIO(image_content))
        
        # å¿…è¦ã«å¿œã˜ã¦ãƒªã‚µã‚¤ã‚ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        max_size = 1024
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
            img = img.resize(new_size, Image.LANCZOS)
        
        # ç”»åƒã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format=img.format or 'JPEG')
        img_bytes = img_byte_arr.getvalue()
        
        # Gemini Vision APIã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        print("Gemini Vision APIã§ç”»åƒã‚’åˆ†æä¸­...")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt_text = f"{system_prompt}\n\n"
        if message:
            prompt_text += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {message}\n\n"
            prompt_text += "ã“ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ç”»åƒã‚’å‚è€ƒã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
        else:
            prompt_text += "ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚ç”»åƒã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã‚’åˆ†æã—ã€ç‰¹å¾´ã‚„çŠ¶æ³ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
        
        # ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt_parts = [
            prompt_text,
            {
                "mime_type": f"image/{img.format.lower() if img.format else 'jpeg'}",
                "data": base64.b64encode(img_bytes).decode('utf-8')
            }
        ]
        
        try:
            # Gemini Vision APIã§å¿œç­”ã‚’ç”Ÿæˆ
            response = vision_model.generate_content(prompt_parts)
            ai_message = response.text
            print(f"Gemini Visionã®å¿œç­”: {ai_message}")
        except Exception as e:
            print(f"Gemini Vision APIã‚¨ãƒ©ãƒ¼: {str(e)}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
            ai_message = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ç”»åƒã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸãƒŠãƒªï¼ã‚¨ãƒ©ãƒ¼: {str(e)}"
        
        # AIã®å¿œç­”ã‚’ãã®ã¾ã¾ä½¿ç”¨
        speech_text = ai_message
        print(f"éŸ³å£°ç”Ÿæˆç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆ: {speech_text}")
        
        if not speech_text.strip():
            raise ValueError("AIã®å¿œç­”ãŒç©ºã§ã™")
        
        # éŸ³å£°ã‚’ç”Ÿæˆ
        print("éŸ³å£°ã‚’ç”Ÿæˆä¸­...")
        sentences = split_text(speech_text)
        audio_segments = []
        
        for sentence in sentences:
            if not sentence.strip():
                continue
                
            try:
                audio_data = await generate_speech(sentence, voice_id)
                if len(audio_data) < 44:  # WAVãƒ˜ãƒƒãƒ€ãƒ¼ã®ã‚µã‚¤ã‚ºã‚ˆã‚Šå°ã•ã„å ´åˆ
                    print(f"è­¦å‘Š: éŸ³å£°ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã¾ã™: {len(audio_data)} bytes")
                    continue
                
                # Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                audio_base64 = base64.b64encode(audio_data).decode('utf-8')
                audio_segments.append(audio_base64)
                print(f"ç”Ÿæˆã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º: {len(audio_base64)} bytes")
            except Exception as e:
                print(f"æ–‡ã®éŸ³å£°ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ
        
        # å¿œç­”ã‚’è¿”ã™
        return {
            'message': ai_message,
            'audio_segments': audio_segments,
            'content_type': 'audio/wav'
        }
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return JSONResponse(
            status_code=500,
            content={
                'message': str(e),
                'error': str(e)
            }
        )

async def run_server():
    # ãƒ›ã‚¹ãƒˆåã‚’å–å¾—
    hostname = socket.gethostname()
    local_ip = socket.gethostbyname(hostname)
    print(f"ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™: http://{local_ip}:8000")
    print(f"Tailscaleã‚¢ãƒ‰ãƒ¬ã‚¹çµŒç”±ã§ã‚‚ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãƒŠãƒªï¼")

    config = uvicorn.Config(
        "main:app",
        host="0.0.0.0",
        port=8000,  # ãƒãƒ¼ãƒˆç•ªå·ã‚’å¤‰æ›´
        reload=True,  # ãƒ›ãƒƒãƒˆãƒªãƒ­ãƒ¼ãƒ‰æœ‰åŠ¹
        reload_dirs=["templates"]  # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚‚ç›£è¦–
    )
    server = uvicorn.Server(config)
    await server.serve()  # éåŒæœŸã§ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•

if __name__ == "__main__":
    asyncio.run(run_server())  # `asyncio.run()` ã§é©åˆ‡ã«åœæ­¢å¯èƒ½ã«ã™ã‚‹